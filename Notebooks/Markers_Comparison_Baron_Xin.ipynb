{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we used two datasets of pancreatic cells. For gene markers we used the Panglao Cell Type Marker database.\n",
    "\n",
    "We used the Baron (2016) dataset for training the neural network (NN) because it has more cells and classes, and we used the Xin (2016) dataset for testing purposes because all of its classes are present in the Baron dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BOTTLENECK = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import read_h5ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Orange.data import Table\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "SPECIES = 'Human'\n",
    "DATASET_BARON_PATH = '/home/mlongar/Data/SingleCellGeneExpression/baron_2016h.h5ad'\n",
    "DATASET_XIN_PATH = '/home/mlongar/Data/SingleCellGeneExpression/xin_2016.h5ad'\n",
    "MARKER_PATH = '/home/mlongar/Data/SingleCellGeneExpression/panglao_gene_markers.tab.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baron_dataset = read_h5ad(DATASET_BARON_PATH)\n",
    "baron_data = baron_dataset.to_df()\n",
    "baron_labels = baron_dataset.obs[\"labels\"]\n",
    "\n",
    "xin_dataset = read_h5ad(DATASET_XIN_PATH)\n",
    "xin_data = xin_dataset.to_df()\n",
    "xin_labels = xin_dataset.obs[\"labels\"]\n",
    "\n",
    "markers = Table(MARKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8569, 20125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Acinar cells, Beta cells, Delta cells, PaSC, Ductal cells, Alpha cells, Other, PP cells, Endothelial cell]\n",
       "Categories (9, object): [Acinar cells, Beta cells, Delta cells, PaSC, ..., Alpha cells, Other, PP cells, Endothelial cell]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(baron_data.shape)\n",
    "baron_labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baron has 8569 cells and 20125 genes.\n",
    "\n",
    "The cells are classified into 9 classes: Acinar cells, Alpha cells, Beta cells, Delta cells, Ductal cells, Endothelial cells, **Other**, PaSC (Pancreatic stellate cells) and PP cells (Gamma cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492, 39851)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Beta cells, Alpha cells, Delta cells, PP cells]\n",
       "Categories (4, object): [Beta cells, Alpha cells, Delta cells, PP cells]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xin_data.shape)\n",
    "xin_labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xin has 1492 cells and 39851 genes.\n",
    "\n",
    "The cells are classified into 4 classes: Alpha cells, Beta cells, Delta cells and PP cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed every cell classified as 'Other' from the Baron dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i, c_type in enumerate(baron_labels.tolist()):\n",
    "    if c_type == 'Other':\n",
    "        to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baron_data = baron_data.drop(baron_data.index[to_drop], axis=0)\n",
    "baron_labels = baron_labels.drop(baron_labels.index[to_drop], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 118 cells.\n",
      "(8451, 20125)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropped {0} cells.\".format(len(to_drop)))\n",
    "print(baron_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removed 118 cells from Baron, leaving us with 8451 left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load marker genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load only the specified marker genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_db = []\n",
    "for meta in markers.metas:\n",
    "    if meta[0] == SPECIES:\n",
    "        markers_db.append(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the used marker genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_markers(data, markers=markers_db):\n",
    "    used_markers = []\n",
    "    for i, gene_name in enumerate(data.columns):\n",
    "        for marker in markers:\n",
    "            if gene_name == marker[1]:\n",
    "                used_markers.append((gene_name, marker))\n",
    "    return used_markers\n",
    "\n",
    "used_markers = get_used_markers(data)\n",
    "new_used_markers = get_used_markers(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_to_keep = []\n",
    "for marker in used_markers:\n",
    "    marker_found = False\n",
    "    for new_marker in new_used_markers:\n",
    "        if marker[0] == new_marker[0] and marker[1][2] == new_marker[1][2]:\n",
    "            markers_to_keep.append(marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(used_markers), len(new_used_markers))\n",
    "print(len(markers_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baron ima 7618 markerjev, Xin pa 7610.\n",
    "\n",
    "Uporabil sem samo tiste, ki so skupni obema. Takih je 7545."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_cell_types(used_markers):\n",
    "    cell_types = OrderedDict()\n",
    "    for marker in used_markers:\n",
    "        c_type = marker[1][2]\n",
    "        gene_name = marker[0]\n",
    "        if c_type in cell_types:\n",
    "            if gene_name not in cell_types[c_type]:\n",
    "                cell_types[c_type].append(gene_name)\n",
    "        else:\n",
    "            cell_types[c_type] = [gene_name]\n",
    "    return cell_types\n",
    "\n",
    "cell_types = get_cell_types(markers_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure every class is in the marker layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_genes(cell_types):\n",
    "    used_genes = []\n",
    "    for c_type in cell_types:\n",
    "        genes = cell_types[c_type]\n",
    "        for gene in genes:\n",
    "            if gene not in used_genes:\n",
    "                used_genes.append(gene)\n",
    "    return used_genes\n",
    "\n",
    "used_genes = get_used_genes(cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ker so celice v datasetih malo drugace poimenovane kot pa v bazi markerjev, sem tukaj naredil en dictionary drugacnih imen in preveril ƒçe katera manjkajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_names = {'PaSC' : 'Pancreatic stellate cells',\n",
    "                'PP cells' : 'Gamma (PP) cells',\n",
    "                'Endothelial cell' : 'Endothelial cells'}\n",
    "\n",
    "used_types = []\n",
    "for c_type in cell_types:\n",
    "    used_types.append(c_type)\n",
    "\n",
    "for c_type in labels.unique():\n",
    "    if c_type not in used_types and c_type not in list(marker_names.keys()):\n",
    "        print(c_type)\n",
    "for c_type in new_labels.unique():\n",
    "    if c_type not in used_types and c_type not in list(marker_names.keys()):\n",
    "        print(c_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uporabil sem samo tiste gene, ki so skupni obema datasetoma in ki so v bazi markerjev (torej so povezani z delnopovezanim slojem v avtoenkoderju).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takih genov je v tem primeru 4173."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene_mask = np.zeros(len(data.columns), dtype=bool)\n",
    "new_gene_mask = np.zeros(len(new_data.columns), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i, keep in enumerate(gene_mask):\n",
    "    gene_name = data.columns[i]\n",
    "    if keep == False and gene_name not in used_genes:\n",
    "        to_drop.append(data.columns[i])\n",
    "\n",
    "new_to_drop = []\n",
    "for i, keep in enumerate(new_gene_mask):\n",
    "    gene_name = new_data.columns[i]\n",
    "    if keep == False and gene_name not in used_genes:\n",
    "        new_to_drop.append(new_data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[1] - len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape[1] - len(new_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unused genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(to_drop, axis=1)\n",
    "new_data = new_data.drop(new_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort columns by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "new_data = new_data.reindex(sorted(new_data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns.values == data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(data.index)\n",
    "data_x = data.reindex(idx)\n",
    "data_y = labels.reindex(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log10 transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.log10(data_x + 1)\n",
    "new_data_x = np.log10(new_data + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seventy = int(data_x.shape[0] * 0.7)\n",
    "fifteen = int(data_x.shape[0] * 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[:seventy]\n",
    "train_y = data_y[:seventy]\n",
    "\n",
    "test_x = data_x[seventy:seventy+fifteen]\n",
    "test_y = data_y[seventy:seventy+fifteen]\n",
    "\n",
    "validation_x = data_x[seventy+fifteen:]\n",
    "validation_y = data_y[seventy+fifteen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tukaj sem definiral delnopovezan sloj markerjev.\n",
    "\n",
    "Sloj ima vozli≈°ƒçe za vsak celƒçni tip, katerega geni so prisotni v obeh bazah. V tem primeru je v sloju markerjev 179 vozli≈°ƒç, ki predstavlja 179 celiƒçnih tipov. Vsako vozli≈°ƒçe (torej celiƒçni tip) je na vhodu povezano samo z geni, ki so njegovi markerji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do delnopovezanega sloja sem pri≈°el tako, da sem vzel polnopovezan sloj in mu dodal masko (matrika enk in niƒçel), ki jo pomno≈æim z matriko ute≈æi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mre≈æo sem treniral 100 epoh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arhitektura\n",
    "|Sloj|Vozli≈°ƒça|\n",
    "|----|--------|\n",
    "|Vhod|4173 (genov)|\n",
    "|Markerji|179 (celiƒçnih tipov)|\n",
    "|Polnopovezan sloj|100|\n",
    "|**Bottleneck**|**25**|\n",
    "|Polnopovezan sloj|100|\n",
    "|*Dropout*|*10%*|\n",
    "|Izhod|4173 (genov)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "from keras.engine.base_layer import InputSpec\n",
    "from tensorflow import convert_to_tensor\n",
    "import tensorflow as tf\n",
    "\n",
    "class Markers(Layer):\n",
    "\n",
    "    def __init__(self, units, weight_mask,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(Markers, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "        \n",
    "        weight_mask = convert_to_tensor(np.transpose(weight_mask), dtype=tf.float32)\n",
    "        self.weight_mask = weight_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        conns = tf.multiply(self.kernel, self.weight_mask)\n",
    "        output = K.dot(inputs, conns)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer':\n",
    "                regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(Markers, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_mask(types, n_dim, num_types, data=data):\n",
    "    mask = np.zeros(shape=(num_types, n_dim))\n",
    "    for i, cell_type in enumerate(types):\n",
    "        for gene in types[cell_type]:\n",
    "            gene_index = data.columns.get_loc(gene)\n",
    "            mask[i][gene_index] = 1.0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Add, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model(input_dim, marker_dim, bottleneck_dim, types=cell_types):\n",
    "    weight_mask = get_weight_mask(types=types, num_types=num_types, n_dim=input_dim)\n",
    "    \n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    marker_layer = Markers(marker_dim, weight_mask=weight_mask, activation='relu')(input_layer)\n",
    "    \n",
    "    dense_in_1 = Dense(100, activation='relu')(marker_layer)\n",
    "    bottleneck_layer = Dense(bottleneck_dim, activation='relu', name='Bottleneck')(dense_in_1)\n",
    "    dense_out_1 = Dense(100, activation='relu')(bottleneck_layer)\n",
    "    dropout = Dropout(0.1)(dense_out_1)\n",
    "    \n",
    "    output_layer = Dense(input_dim, activation='relu', name='Output')(dropout)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    marker_model = Model(input_layer, marker_layer)\n",
    "    marker_model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    encoder_model = Model(input_layer, bottleneck_layer)\n",
    "    encoder_model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model, marker_model, encoder_model\n",
    "\n",
    "def train_model(model, data, validation_data, test_data, epochs=30, batch_size=256, verbose=1, callbacks=[]):\n",
    "    history = model.fit(data, data,\n",
    "               epochs=epochs, batch_size=batch_size,\n",
    "               validation_data=(validation_data, validation_data),\n",
    "               callbacks=callbacks,\n",
    "               verbose=verbose)\n",
    "    loss = model.evaluate(test_data, test_data)\n",
    "    return (history, loss)\n",
    "\n",
    "def draw_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss', c='orange')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = train_x.shape[1]\n",
    "num_types = len(cell_types)\n",
    "\n",
    "model, marker_model, encoder_model = build_model(input_dim=n_genes,\n",
    "                                                 marker_dim=num_types,\n",
    "                                                 bottleneck_dim=BOTTLENECK,\n",
    "                                                 types=cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history, loss = train_model(model, train_x, validation_x, test_x, epochs=EPOCHS, verbose=0, callbacks=[])#tensorboard\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('markersonly_comparison.h5')\n",
    "marker_model.save('markersonly_comparison_marker.h5')\n",
    "encoder_model.save('markersonly_comparison_encoder.h5')\n",
    "\n",
    "model.save_weights('markersonly_comparison_weights.h5')\n",
    "marker_model.save_weights('markersonly_comparison_marker_weights.h5')\n",
    "encoder_model.save_weights('markersonly_comparison_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(cell_types, cell_activations, graph_labels):\n",
    "    types_list = list(cell_types.items())\n",
    "    top3s = []\n",
    "    top3s_act = []\n",
    "    for cell in cell_activations:\n",
    "        top3 = cell.argsort()[-3:][::-1]\n",
    "        top3types = [types_list[i][0] for i in top3]\n",
    "        top3s.append(top3types)\n",
    "        \n",
    "        act = np.zeros((len(cell_activations[0]),))\n",
    "        for i in top3:\n",
    "            act[i] = cell[i]\n",
    "        top3s_act.append(act)\n",
    "\n",
    "    n = 0\n",
    "    correct = 0\n",
    "    for i in range(len(top3s)):\n",
    "        prediction = top3s[i][0]\n",
    "        label = graph_labels.iloc[i]\n",
    "\n",
    "        if str(prediction) == 'nan' or str(label) == 'nan':\n",
    "            continue\n",
    "\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "\n",
    "        elif label in marker_names.keys():\n",
    "            if marker_names[label] == prediction:\n",
    "                correct += 1\n",
    "        n += 1\n",
    "\n",
    "    print(\"Correct predictions: {c} out of {n} ({p}%)\".format(c=correct, n=n, p=round(100 * (correct/n), 2)))\n",
    "    print(\"Dropped {d} cells\".format(d=len(cell_activations) - n))\n",
    "    return top3s_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_activations = marker_model.predict(test_x)\n",
    "bottleneck_activations = encoder_model.predict(test_x)\n",
    "graph_labels = test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mre≈æa pravilno klasificira 82% testnih podatkov (iz baze na kateri se je uƒçila)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top3 = get_results(cell_types, cell_activations, graph_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spodnji graf prikazuje aktivacije tipov celic. Razvidno je, da izstopa samo en celiƒçni tip, ostali tipi pa izrecno manj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(cell_activations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cell_activations = marker_model.predict(new_data_x)\n",
    "new_bottleneck_activations = encoder_model.predict(new_data_x)\n",
    "new_graph_labels = new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mre≈æa pravilno klasificira 86% ƒçisto novih podatkov iz druge baze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_top3 = get_results(cell_types, new_cell_activations, new_graph_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_color(pastel_factor = 0.5):\n",
    "    pastel_factor = random.uniform(0, 1.0)\n",
    "    return [(x+pastel_factor)/(1.0+pastel_factor) for x in [random.uniform(0,1.0) for i in [1,2,3]]]\n",
    "\n",
    "colours = {}\n",
    "for label in graph_labels.unique():\n",
    "    colour = (get_random_color())\n",
    "    colours.update({label:colour})\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = list(range(0, len(colours.values()) * 2, 2))\n",
    "y = [0]*len(x)\n",
    "c = list(colours.values())\n",
    "\n",
    "ax.scatter(x,y,s=400,c=c)\n",
    "ax.set_title('Plot with Different Marker Color, matplotlib and plotly')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"Data/Marker_Colours.pickle\",\"rb\")\n",
    "colours = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"Data/Marker_Colours.pickle\",\"wb\")\n",
    "pickle.dump(colours, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import OrderedDict\n",
    "import operator\n",
    "\n",
    "tnse = TSNE()\n",
    "pca = PCA()\n",
    "    \n",
    "def draw_graph(x, y, model, colours, graph_name=''):\n",
    "    tsne_out = model.fit_transform(x)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for i, entry in enumerate(tsne_out):\n",
    "        plt.scatter(entry[0], entry[1], color=colours[y.iloc[i]], label=y.iloc[i])\n",
    "    \n",
    "    handles, plt_labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(plt_labels, handles))\n",
    "    by_label = OrderedDict(sorted(by_label.items()))\n",
    "\n",
    "    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0., 1, 0, .1))\n",
    "\n",
    "    plt.title(graph_name)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_graph(cell_activations, graph_labels, tnse, colours, graph_name='TSNE of marker activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_graph(new_cell_activations, new_graph_labels, tnse, colours, graph_name='TSNE of marker activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_comparison(x, y, new_alpha = 1.0, preloaded_tsne=None, title=''):\n",
    "    if preloaded_tsne is None:\n",
    "        tsne_out = tnse.fit_transform(x)\n",
    "    else:\n",
    "        tsne_out = preloaded_tsne\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for i, entry in enumerate(tsne_out):\n",
    "        colour = colours[y.iloc[i]]\n",
    "        alpha = 1.0\n",
    "        marker = '.'\n",
    "        if(i <= test_x.shape[0]):\n",
    "            alpha = new_alpha\n",
    "            marker = 'x'\n",
    "        plt.scatter(entry[0], entry[1], color=colour, label=y.iloc[i], alpha=alpha, marker=marker)\n",
    "\n",
    "    handles, plt_labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(plt_labels, handles))\n",
    "    by_label = OrderedDict(sorted(by_label.items()))\n",
    "\n",
    "    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0., 1, 0, .1))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #return tsne_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Na spodnjem grafu lahko opazi≈°, da se batch effect ≈°e vedno opazi, tudi na aktivacijah markerjev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_x.append(new_data_x)\n",
    "y = test_y.append(new_labels)\n",
    "compare_cell_activations = encoder_model.predict(x)\n",
    "tsne_out = draw_comparison(compare_cell_activations, y, new_alpha=0.2, title='Combined TSNE of marker activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_comparison(np.vstack((top3, new_top3)), y, new_alpha=0.2, title='Combined TSNE of top 3 activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tukaj sem vzel nove podatke in jih vrgel v avtoenkoder.**\n",
    "\n",
    "**Nato sem vzel izhodne podatke avtoenkoderja ter vzel njihove aktivacije sloja markerjev.**\n",
    "\n",
    "**Tako sem dobil nove rezultate, ki so bili konsistentno bolj≈°i. V tem primeru za 11%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moja hipoteza je, da se tako delno znebimo batch effecta in zato dobimo bolj≈°e rezultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = model.predict(new_data_x)\n",
    "reconstruction = pd.DataFrame(reconstruction, columns=new_data_x.columns)\n",
    "reconstructed_cell_activations = marker_model.predict(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(reconstructed_cell_activations, new_graph_labels, tnse, colours,\n",
    "           graph_name='TSNE of reconstructed marker activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_results(cell_types, reconstructed_cell_activations, new_graph_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudi pri teh podatkih batch effect ≈°e vedno ostane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_x.append(reconstruction)\n",
    "y = test_y.append(new_labels)\n",
    "compare_cell_activations = encoder_model.predict(x)\n",
    "tsne_out = draw_comparison(compare_cell_activations, y, new_alpha=0.2, title='Combined TSNE of marker activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = pd.DataFrame(new_data_x)\n",
    "out_data = pd.DataFrame(data=model.predict(new_data_x))\n",
    "in_data.to_pickle('Data/in_data_markersonly.pickle')\n",
    "out_data.to_pickle('Data/out_data_markersonly.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
