{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path\n",
    "import sys\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "sys.path.append(path.join(\"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {\n",
       "    float: left;\n",
       "}\n",
       "\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {\n",
    "    float: left;\n",
    "}\n",
    "\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we used two datasets of pancreatic cells. For gene markers, we used the Panglao Cell Type Marker database.\n",
    "\n",
    "We used the Baron (2016) dataset for training the neural network (NN) because it has more cells and classes, and we used the Xin (2016) dataset for testing purposes because all of its classes are present in the Baron dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import saly\n",
    "import saly.backend as S\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SPECIES = 'Human'\n",
    "DATA_PATH = '/home/mlongar/Data/SingleCellGeneExpression/'\n",
    "#DATA_PATH = '/Users/MarkDavidLongar/Documents/Coding/MachineLearning/Data/'\n",
    "#DATA_PATH = 'D:/Data/SingleCellGeneExpression/'\n",
    "DATASET_BARON_PATH = DATA_PATH + 'baron_2016h.h5ad' \n",
    "DATASET_XIN_PATH = DATA_PATH + 'xin_2016.h5ad'\n",
    "MARKER_PATH = DATA_PATH + 'panglao_gene_markers.tab.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baron_data, baron_labels = saly.load_h5ad(DATASET_BARON_PATH)\n",
    "xin_data, xin_labels = saly.load_h5ad(DATASET_XIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8569, 20125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Acinar cells, Beta cells, Delta cells, PaSC, Ductal cells, Alpha cells, Other, PP cells, Endothelial cell]\n",
       "Categories (9, object): [Acinar cells, Beta cells, Delta cells, PaSC, ..., Alpha cells, Other, PP cells, Endothelial cell]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(baron_data.shape)\n",
    "baron_labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baron has 8569 cells and 20125 genes.\n",
    "\n",
    "The cells are classified into 9 classes: Acinar cells, Alpha cells, Beta cells, Delta cells, Ductal cells, Endothelial cells, ***Other***, PaSC (i.e. Pancreatic stellate cells) and PP cells (i.e. Gamma cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492, 39851)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Beta cells, Alpha cells, Delta cells, PP cells]\n",
       "Categories (4, object): [Beta cells, Alpha cells, Delta cells, PP cells]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xin_data.shape)\n",
    "xin_labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xin has 1492 cells and 39851 genes.\n",
    "\n",
    "The cells are classified into 4 classes: Alpha cells, Beta cells, Delta cells and PP cells (i.e. Gamma cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed every cell classified as 'Other' from the Baron dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 118 cell(s). New shape: (8451, 20125)\n"
     ]
    }
   ],
   "source": [
    "baron_data, baron_labels = saly.drop_rows(baron_data, baron_labels, ['Other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removed 118 cells from Baron, leaving us with 8451 left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load marker genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure to only load the Human marker genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_db = saly.load_markers(MARKER_PATH, SPECIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the markers and only keep those found in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markers = saly.get_mutual_markers([baron_data.columns, xin_data.columns], markers_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this because we want to train the network only on the marker genes found in both datasets, and drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(S.get_used_markers(baron_data.columns, markers_db)), len(S.get_used_markers(xin_data.columns, markers_db)))\n",
    "print(len(markers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baron has 7618 markers, and Xin has 7610.\n",
    "\n",
    "We used only those found in both datasets (7545)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that in this context* ***Marker ≠ Marker Gene*** *because multiple cell types (i.e. markers) can have the same marker gene and so in this context, the number 7545 means 7545 connections in the partially-connected Marker Layer between the cell types and the genes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure every class is in the marker layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some cell types are differently labelled in the marker database, we created a dictionary of aliases.\n",
    "\n",
    "We also make sure to print out any label that cannot be found in either the list of markers or in the dictionary of aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_aliases = {'PaSC' : 'Pancreatic stellate cells',\n",
    "                  'PP cells' : 'Gamma (PP) cells',\n",
    "                  'Endothelial cell' : 'Endothelial cells'}\n",
    "\n",
    "saly.check_labels([baron_labels, xin_labels], markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unused genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used only the genes found in both datasets and the marker gene database, and therefore, we will connect with the partially-connected marker layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 15952 gene(s). New shape: (8451, 4173)\n",
      "Dropped 35678 gene(s). New shape: (1492, 4173)\n"
     ]
    }
   ],
   "source": [
    "baron_data_ = saly.drop_unused_genes(baron_data, markers)\n",
    "xin_data_ = saly.drop_unused_genes(xin_data, markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this operation we are left with 4173 genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model we define a partially-connected Marker Layer.\n",
    "\n",
    "The layer has a node for each cell type whose genes are present in both data sets.\n",
    "In this case, there are 179 nodes in the marker layer representing 179 cell types. \n",
    "\n",
    "We only connect nodes (i.e. the cell types) in the marker layer to their marker genes at the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We constructed the partially connected marker layer by taking a dense layer and adding a connection mask (a binary matrix) to it, which we multiply with the output matrix.\n",
    "\n",
    "We trained the network for 100 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network we used two losses:\n",
    "\n",
    "    1) A loss that measured the network's classification accuracy (cross entropy)\n",
    "    \n",
    "    2) A loss that measured the network's reconstruction accuracy (mean square error)\n",
    "           During training we scaled the MSE score 100x to compensate for the losses' different scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Architecture\n",
    "|Layer|Nodes|\n",
    "|-----|------|\n",
    "|Input|4173 (genes)|\n",
    "|Markers|179 (cell types)|\n",
    "|Dense layer|100|\n",
    "|**Bottleneck**|**25**|\n",
    "|Dense layer|100|\n",
    "|*Dropout*|*10%*|\n",
    "|Output|4173 (genes)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, marker_model, encoder_model = saly.build_model(baron_data_, markers, supervised=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Random Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "gene_intersection = baron_data.columns.intersection(xin_data.columns)\n",
    "random_genes = sample(gene_intersection.to_list(), baron_data_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_to_drop(data, to_keep):\n",
    "    return [gene for gene in data.columns if gene not in to_keep]\n",
    "\n",
    "baron_data= baron_data.drop(get_to_drop(baron_data, random_genes), axis=1)\n",
    "xin_data = xin_data.drop(get_to_drop(xin_data, random_genes), axis=1)\n",
    "\n",
    "baron_data= baron_data.reindex(sorted(baron_data.columns), axis=1)\n",
    "xin_data = xin_data.reindex(sorted(xin_data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure the data sets' shapes match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saly.check_shape([baron_data, xin_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle, log10 transform and split the data into 70%, 15%, 15% splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (validation_x, validation_y), (test_x, test_y) = saly.preprocess_data(baron_data, baron_labels,\n",
    "                                                                                          train=0.7, validation=0.15,\n",
    "                                                                                          test=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log10 transform the Xin data, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin_data = S.log_10(xin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5915 samples, validate on 1267 samples\n",
      "Epoch 1/200\n",
      " - 3s - loss: 11.4503 - cell_activations_loss: 9.6514 - output_loss: 0.0180 - cell_activations_marker_prediction_metric: 0.0183 - val_loss: 10.9006 - val_cell_activations_loss: 9.5997 - val_output_loss: 0.0130 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 2/200\n",
      " - 2s - loss: 10.6611 - cell_activations_loss: 9.3978 - output_loss: 0.0126 - cell_activations_marker_prediction_metric: 0.0183 - val_loss: 10.5307 - val_cell_activations_loss: 9.3400 - val_output_loss: 0.0119 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 3/200\n",
      " - 3s - loss: 10.3138 - cell_activations_loss: 9.1407 - output_loss: 0.0117 - cell_activations_marker_prediction_metric: 0.0183 - val_loss: 10.2094 - val_cell_activations_loss: 9.0767 - val_output_loss: 0.0113 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 4/200\n",
      " - 2s - loss: 10.0089 - cell_activations_loss: 8.8812 - output_loss: 0.0113 - cell_activations_marker_prediction_metric: 0.0183 - val_loss: 9.9168 - val_cell_activations_loss: 8.8142 - val_output_loss: 0.0110 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 5/200\n",
      " - 2s - loss: 9.7271 - cell_activations_loss: 8.6210 - output_loss: 0.0111 - cell_activations_marker_prediction_metric: 0.0184 - val_loss: 9.6379 - val_cell_activations_loss: 8.5489 - val_output_loss: 0.0109 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 6/200\n",
      " - 3s - loss: 9.4520 - cell_activations_loss: 8.3603 - output_loss: 0.0109 - cell_activations_marker_prediction_metric: 0.0186 - val_loss: 9.3658 - val_cell_activations_loss: 8.2854 - val_output_loss: 0.0108 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 7/200\n",
      " - 3s - loss: 9.1818 - cell_activations_loss: 8.1007 - output_loss: 0.0108 - cell_activations_marker_prediction_metric: 0.0189 - val_loss: 9.0941 - val_cell_activations_loss: 8.0235 - val_output_loss: 0.0107 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 8/200\n",
      " - 2s - loss: 8.9150 - cell_activations_loss: 7.8447 - output_loss: 0.0107 - cell_activations_marker_prediction_metric: 0.0189 - val_loss: 8.8283 - val_cell_activations_loss: 7.7670 - val_output_loss: 0.0106 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 9/200\n",
      " - 2s - loss: 8.6539 - cell_activations_loss: 7.5921 - output_loss: 0.0106 - cell_activations_marker_prediction_metric: 0.0193 - val_loss: 8.5701 - val_cell_activations_loss: 7.5121 - val_output_loss: 0.0106 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 10/200\n",
      " - 2s - loss: 8.3985 - cell_activations_loss: 7.3419 - output_loss: 0.0106 - cell_activations_marker_prediction_metric: 0.0199 - val_loss: 8.3100 - val_cell_activations_loss: 7.2589 - val_output_loss: 0.0105 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 11/200\n",
      " - 3s - loss: 8.1459 - cell_activations_loss: 7.0951 - output_loss: 0.0105 - cell_activations_marker_prediction_metric: 0.0205 - val_loss: 8.0578 - val_cell_activations_loss: 7.0108 - val_output_loss: 0.0105 - val_cell_activations_marker_prediction_metric: 0.0126\n",
      "Epoch 12/200\n",
      " - 2s - loss: 7.9013 - cell_activations_loss: 6.8545 - output_loss: 0.0105 - cell_activations_marker_prediction_metric: 0.0210 - val_loss: 7.8133 - val_cell_activations_loss: 6.7700 - val_output_loss: 0.0104 - val_cell_activations_marker_prediction_metric: 0.0134\n",
      "Epoch 13/200\n",
      " - 2s - loss: 7.6608 - cell_activations_loss: 6.6188 - output_loss: 0.0104 - cell_activations_marker_prediction_metric: 0.0215 - val_loss: 7.5734 - val_cell_activations_loss: 6.5346 - val_output_loss: 0.0104 - val_cell_activations_marker_prediction_metric: 0.0134\n",
      "Epoch 14/200\n",
      " - 2s - loss: 7.4268 - cell_activations_loss: 6.3893 - output_loss: 0.0104 - cell_activations_marker_prediction_metric: 0.0223 - val_loss: 7.3412 - val_cell_activations_loss: 6.3046 - val_output_loss: 0.0104 - val_cell_activations_marker_prediction_metric: 0.0134\n",
      "Epoch 15/200\n",
      " - 3s - loss: 7.2013 - cell_activations_loss: 6.1672 - output_loss: 0.0103 - cell_activations_marker_prediction_metric: 0.0230 - val_loss: 7.1184 - val_cell_activations_loss: 6.0827 - val_output_loss: 0.0104 - val_cell_activations_marker_prediction_metric: 0.0158\n",
      "Epoch 16/200\n",
      " - 3s - loss: 6.9842 - cell_activations_loss: 5.9526 - output_loss: 0.0103 - cell_activations_marker_prediction_metric: 0.0235 - val_loss: 6.9007 - val_cell_activations_loss: 5.8690 - val_output_loss: 0.0103 - val_cell_activations_marker_prediction_metric: 0.0166\n",
      "Epoch 17/200\n",
      " - 2s - loss: 6.7748 - cell_activations_loss: 5.7467 - output_loss: 0.0103 - cell_activations_marker_prediction_metric: 0.0243 - val_loss: 6.6923 - val_cell_activations_loss: 5.6629 - val_output_loss: 0.0103 - val_cell_activations_marker_prediction_metric: 0.0158\n",
      "Epoch 18/200\n",
      " - 2s - loss: 6.5745 - cell_activations_loss: 5.5481 - output_loss: 0.0103 - cell_activations_marker_prediction_metric: 0.0254 - val_loss: 6.4932 - val_cell_activations_loss: 5.4664 - val_output_loss: 0.0103 - val_cell_activations_marker_prediction_metric: 0.0174\n",
      "Epoch 19/200\n",
      " - 2s - loss: 6.3830 - cell_activations_loss: 5.3589 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0267 - val_loss: 6.3062 - val_cell_activations_loss: 5.2779 - val_output_loss: 0.0103 - val_cell_activations_marker_prediction_metric: 0.0205\n",
      "Epoch 20/200\n",
      " - 2s - loss: 6.1998 - cell_activations_loss: 5.1787 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0309 - val_loss: 6.1231 - val_cell_activations_loss: 5.1005 - val_output_loss: 0.0102 - val_cell_activations_marker_prediction_metric: 0.0253\n",
      "Epoch 21/200\n",
      " - 2s - loss: 6.0284 - cell_activations_loss: 5.0089 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0363 - val_loss: 5.9544 - val_cell_activations_loss: 4.9322 - val_output_loss: 0.0102 - val_cell_activations_marker_prediction_metric: 0.0324\n",
      "Epoch 22/200\n",
      " - 2s - loss: 5.8662 - cell_activations_loss: 4.8485 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0411 - val_loss: 5.7944 - val_cell_activations_loss: 4.7741 - val_output_loss: 0.0102 - val_cell_activations_marker_prediction_metric: 0.0379\n",
      "Epoch 23/200\n",
      " - 2s - loss: 5.7150 - cell_activations_loss: 4.6985 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0477 - val_loss: 5.6442 - val_cell_activations_loss: 4.6255 - val_output_loss: 0.0102 - val_cell_activations_marker_prediction_metric: 0.0505\n",
      "Epoch 24/200\n",
      " - 2s - loss: 5.5739 - cell_activations_loss: 4.5588 - output_loss: 0.0102 - cell_activations_marker_prediction_metric: 0.0561 - val_loss: 5.5054 - val_cell_activations_loss: 4.4884 - val_output_loss: 0.0102 - val_cell_activations_marker_prediction_metric: 0.0608\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3e07ed19580b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = saly.train_model(model, train_x, train_y, markers, marker_aliases,\n\u001b[0;32m----> 2\u001b[0;31m                            EPOCHS, validation_data=(validation_x, validation_y), verbose=2);\n\u001b[0m",
      "\u001b[0;32m~/MarkerGenes/saly/deep/model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data, labels, markers, marker_aliases, epochs, validation_data, batch_size, verbose, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                         verbose=verbose)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/MG/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda/envs/MG/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/MG/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/MG/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = saly.train_model(model, train_x, train_y, markers, marker_aliases,\n",
    "                           EPOCHS, validation_data=(validation_x, validation_y), verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a930a0bba7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msaly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker_aliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "saly.plot_model_history(history)\n",
    "saly.test_model(model, test_x, test_y, markers, marker_aliases);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE()\n",
    "colours = S.load_label_colours('../Data/baron_xin_label_colours.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baron predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baron_cell_activations = marker_model.predict(test_x)\n",
    "baron_bottleneck_activations = encoder_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_confusion_matrix(test_y, baron_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saly.get_results(test_y, baron_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saly.get_average_auc(test_y, baron_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows the mean cell type activations. Note that only one cell type explicitly activates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saly.plot_activation_distribution(baron_cell_activations, markers,\n",
    "                                  title='Average distribution of Baron cell type activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network correctly classifies 98% of test data from the training database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.compare_embeddings([baron_cell_activations, test_y], [baron_bottleneck_activations, test_y],\n",
    "                        tsne, colours=colours, alpha=0.8,\n",
    "                        graph_titles=['tSNE of Baron cell type activations', 'tSNE of Baron bottleneck activations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xin predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin_cell_activations = marker_model.predict(xin_data)\n",
    "xin_bottleneck_activations = encoder_model.predict(xin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_confusion_matrix(xin_labels, xin_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.get_results(xin_labels, xin_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.get_average_auc(xin_labels, xin_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.plot_activation_distribution(xin_cell_activations, markers,\n",
    "                                  title='Average distribution of Xin cell type activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network correctly classifies almost 100% of data from a completely new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saly.compare_embeddings([xin_cell_activations, xin_labels],\n",
    "                        [xin_bottleneck_activations, xin_labels],\n",
    "                        tsne, colours=colours, alpha=0.8,\n",
    "                        graph_titles=['tSNE of Xin cell type activations',\n",
    "                                      'tSNE of Xin bottleneck activations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took the Xin data set and run them through the autoencoder.\n",
    "\n",
    "Then we took the autoencoder's output (i.e. the reconstructed data) and ran that data through the autoencoder again, this time looking at the Marker layer's cell type activations.\n",
    "\n",
    "The cell type activations of the reconstructed data give similar, sometimes worse, but almost never better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = model.predict(xin_data)[1]\n",
    "reconstruction = pd.DataFrame(reconstruction, columns=xin_data.columns)\n",
    "reconstructed_cell_activations = marker_model.predict(reconstruction)\n",
    "reconstructed_bottleneck_activations = encoder_model.predict(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_confusion_matrix(xin_labels, reconstructed_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.get_results(xin_labels, reconstructed_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.get_average_auc(xin_labels, reconstructed_cell_activations, markers, marker_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.plot_activation_distribution(reconstructed_cell_activations, markers,\n",
    "                                  title='Average distribution of reconstructed Xin cell type activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network correctly classifies almost 99% of reconstructed Xin data, similar to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.compare_embeddings([reconstructed_cell_activations, xin_labels],\n",
    "                        [reconstructed_bottleneck_activations, xin_labels],\n",
    "                        tsne, colours=colours, alpha=0.8,\n",
    "                        graph_titles=['tSNE of reconstruced Xin cell type activations',\n",
    "                                      'tSNE of reconstruced Xin bottleneck activations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see if our marker activations still have batch effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saly.draw_comparison([baron_cell_activations, test_y], [xin_cell_activations, xin_labels] ,tsne, colours=colours,\n",
    "                     graph_title='Combined cell activations of Baron and Xin cell type activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_comparison([baron_cell_activations, test_y], [reconstructed_cell_activations, xin_labels], tsne,\n",
    "                     colours=colours, \n",
    "                     graph_title='Combined cell activations of Baron and the reconstructed Xin cell type activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried to see if taking only the top 3 cell activations would help us remedy the batch effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baron_top_3 = saly.get_top_activations(3, baron_cell_activations)\n",
    "xin_top_3 = saly.get_top_activations(3, xin_cell_activations)\n",
    "reconstructed_top_3 = saly.get_top_activations(3, reconstructed_cell_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_comparison([baron_top_3, test_y], [xin_top_3, xin_labels], tsne, colours=colours,\n",
    "                     graph_title='Combined data of top 3 activations of Baron and Xin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saly.draw_comparison([baron_top_3, test_y], [reconstructed_top_3, xin_labels], tsne, colours=colours,\n",
    "                     graph_title='Combined data of top 3 activations of Baron and reconstruced Xin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
